{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from lxml import html\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dou_interaction:\n",
    "    \n",
    "    def __init__(self, url='https://jobs.dou.ua/vacancies/?search=data+engineer'):\n",
    "        #xpath for getting all links to jobs descriptions\n",
    "        self.xpath_vacancy_link = \"//div[@class='vacancy' and @_id]//a[@class='vt' and @href]\"\n",
    "        # xpath for an element which contains token\n",
    "        self.xpath_script = \"//script[contains(text(),'window.CSRF_TOKEN = \\\"')]\"\n",
    "        #token\n",
    "        self.csrf_token = None\n",
    "        #all links to jobs\n",
    "        self.urls = []\n",
    "        #for 1-st request, changing User-Agent\n",
    "        self.headers={\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0'\n",
    "            }\n",
    "        #changing headers for post-request\n",
    "        self.headers_post = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0',\n",
    "            'X-Requested-With': 'XMLHttpRequest',\n",
    "            'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "            'Referer': 'https://jobs.dou.ua/vacancies/?search=data+engineer',\n",
    "            }\n",
    "        #directory for saving html pages\n",
    "        self.dir = \"result\\\\\"\n",
    "        #link to main page\n",
    "        self.url = url\n",
    "        #changing a link for a post request\n",
    "        self.get_url_post(url)\n",
    "    \n",
    "    def get_url_post(self, url):\n",
    "        start = url.index('?')\n",
    "        search_query = url[start:]\n",
    "        self.url_post = 'https://jobs.dou.ua/vacancies/xhr-load/'+search_query.replace('+','%20')\n",
    "        \n",
    "    def get_vacancies_links(self):\n",
    "        #making request with headers, getting text\n",
    "        self.session = requests.Session()\n",
    "        search_page = self.session.get(url=self.url, headers=self.headers).text\n",
    "        root = html.fromstring(search_page)\n",
    "        \n",
    "        #getting token\n",
    "        script = root.xpath(self.xpath_script)[0].text\n",
    "        pattern = r'window.CSRF_TOKEN = \"(.*?)\"'\n",
    "        self.csrf_token = re.findall(pattern, script)[0] \n",
    "        \n",
    "        #getting all links to vacancies\n",
    "        self.get_links(page=search_page)\n",
    "        while True:\n",
    "            #getting more links\n",
    "            json_response = self.get_add_vacancies(count=len(self.urls))\n",
    "            #adding them to list of links\n",
    "            self.get_links(page=json_response.get('html'))\n",
    "            #if link is the last one - break\n",
    "            if json_response.get('last'):\n",
    "                break;\n",
    "\n",
    "    def get_links(self, page):\n",
    "        root = html.fromstring(page)\n",
    "        vacancies_links = root.xpath(self.xpath_vacancy_link)\n",
    "        for link in vacancies_links:\n",
    "            self.urls.append(link.attrib['href'])\n",
    "\n",
    "    def get_add_vacancies(self,count:int):\n",
    "        #параметрі пост запроса, заполнение\n",
    "        my_obj = {'csrfmiddlewaretoken': self.csrf_token, 'count': count}\n",
    "        x = self.session.post(url=self.url_post, data=my_obj, headers=self.headers_post)\n",
    "        return x.json()\n",
    "    \n",
    "    def get_page_content(self, url:str):\n",
    "        page = self.session.get(url, headers=self.headers).text\n",
    "        return page\n",
    "    \n",
    "    def get_and_save_all_pages(self):\n",
    "        self.get_vacancies_links()\n",
    "        \n",
    "        for num, url in enumerate(self.urls):\n",
    "            text_page = self.get_page_content(url=url)\n",
    "            with open(self.dir+\"page_\"+str(num)+\".html\",'wt', encoding='utf8') as file:\n",
    "                file.write(text_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dou_int = Dou_interaction()\n",
    "dou_int.get_and_save_all_pages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
