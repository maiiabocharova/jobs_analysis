{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = open('dou_vacancies.csv', 'w', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['headline', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'dou/rezult'\n",
    "for filename in os.listdir(directory):    \n",
    "    file = codecs.open(directory + '/' + filename, \"r\", 'utf-8')\n",
    "    soup = BeautifulSoup(file)\n",
    "    headline = soup.find('h1', class_=\"g-h2\").get_text()\n",
    "    vacancy = soup.find('div', class_=\"l-vacancy\")\n",
    "    descriptions = vacancy.find_all('div', class_=\"text b-typo vacancy-section\")\n",
    "    text = ''\n",
    "    for description in descriptions:\n",
    "        text += description.get_text()\n",
    "    csv_writer.writerow([headline, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dou_vacancies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior ML engineer (Computer Vision, 3d)</td>\n",
       "      <td>\\r\\n— Python— хорошая математическая база для ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Java/BigData Engineer</td>\n",
       "      <td>\\r\\nExperience in Java development (5 years+);...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java Engineer for HighLoad/BigData project | SM</td>\n",
       "      <td>\\r\\n— Professional Java experience 3+ years— O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>\\r\\n— 2+ years experience with Python, includi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>\\r\\n— 2+ years of hands-on experience as a Dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          headline  \\\n",
       "0         Junior ML engineer (Computer Vision, 3d)   \n",
       "1                     Senior Java/BigData Engineer   \n",
       "2  Java Engineer for HighLoad/BigData project | SM   \n",
       "3                                     NLP Engineer   \n",
       "4                                    Data Engineer   \n",
       "\n",
       "                                         description  \n",
       "0  \\r\\n— Python— хорошая математическая база для ...  \n",
       "1  \\r\\nExperience in Java development (5 years+);...  \n",
       "2  \\r\\n— Professional Java experience 3+ years— O...  \n",
       "3  \\r\\n— 2+ years experience with Python, includi...  \n",
       "4  \\r\\n— 2+ years of hands-on experience as a Dat...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "punctuation += '—'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "punct = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(u'\\xa0', u' ')\n",
    "    text_eng = re.sub('[^a-zA-Z0-9-+ ]+', '', text)\n",
    "    return text_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    lst = word_tokenize(text)\n",
    "    lst = [word for word in lst if word not in stop and word not in punct]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_nouns(lst):\n",
    "    new_lst = [word for (word,pos) in nltk.pos_tag(lst) if pos[:2] == 'NN']\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df.description.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df.description.apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df.description.apply(leave_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_data_engineer'] = df['headline'].apply(lambda x: 'data' in x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>is_data_engineer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior ML engineer (Computer Vision, 3d)</td>\n",
       "      <td>[Python, machine, learning, Numpy, Pandas, Sci...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Java/BigData Engineer</td>\n",
       "      <td>[Experience, Java, development, years+Experien...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Java Engineer for HighLoad/BigData project | SM</td>\n",
       "      <td>[Java, experience, years, OOPdesign, proficien...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>[years, Python, engineering, experience, API, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>[years, experience, Data, Engineer, experience...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          headline  \\\n",
       "0         Junior ML engineer (Computer Vision, 3d)   \n",
       "1                     Senior Java/BigData Engineer   \n",
       "2  Java Engineer for HighLoad/BigData project | SM   \n",
       "3                                     NLP Engineer   \n",
       "4                                    Data Engineer   \n",
       "\n",
       "                                         description  is_data_engineer  \n",
       "0  [Python, machine, learning, Numpy, Pandas, Sci...             False  \n",
       "1  [Experience, Java, development, years+Experien...              True  \n",
       "2  [Java, experience, years, OOPdesign, proficien...              True  \n",
       "3  [years, Python, engineering, experience, API, ...             False  \n",
       "4  [years, experience, Data, Engineer, experience...              True  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     118\n",
       "False     38\n",
       "Name: is_data_engineer, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_data_engineer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineers = df.query('is_data_engineer == True').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      [Experience, Java, development, years+Experien...\n",
       "2      [Java, experience, years, OOPdesign, proficien...\n",
       "4      [years, experience, Data, Engineer, experience...\n",
       "5      [Clients, mission, everyone, eat, Company, mea...\n",
       "6      [years, Scala, development, cloud, services, A...\n",
       "                             ...                        \n",
       "151    [Experience, data, analytics, data, engineerin...\n",
       "152    [cross-platformcross-browser, QA, solution, do...\n",
       "153    [Fractal, Kyiv, team, position, junior, data, ...\n",
       "154    [years, experience, software, development, pri...\n",
       "155    [Job, SummaryDevelop, Rokus, edge, delivery, i...\n",
       "Name: description, Length: 118, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engineers['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineers['text'] = df_engineers['description'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = df_engineers['text'].str.cat(sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_technologies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    if ent.label_ != 'DATE':\n",
    "        list_technologies.append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_technologies = set(list_technologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AI',\n",
       " 'AIML',\n",
       " 'ALM',\n",
       " 'AREPassionate',\n",
       " 'AWS',\n",
       " 'AWS Azure GCP Airflow',\n",
       " 'AWS Azure GCP Knowledge',\n",
       " 'AWS Azure GCPData',\n",
       " 'AWS Azure SaaS',\n",
       " 'AWS Big Data Data Engineer AWS Data Lake Distributed Data Mesh Python',\n",
       " 'AWS Cloud Process',\n",
       " 'AWS EMR Lambda S3',\n",
       " 'AWS Expertise',\n",
       " 'AWS GCP',\n",
       " 'AWS GCP Ability',\n",
       " 'AWS GCP AzureCommercial',\n",
       " 'AWS GCP BigQueryBe Object',\n",
       " 'AWS Good',\n",
       " 'AWS QuickSight Google Data',\n",
       " 'AWS Redshift',\n",
       " 'AWS Step',\n",
       " 'AWS Strong',\n",
       " 'AWSWorking Conditions Premium',\n",
       " 'AWSWriting',\n",
       " 'Administer Bigquery',\n",
       " 'AgensGraph',\n",
       " 'Agile ScrumGood',\n",
       " 'Agile Software Development',\n",
       " 'Aiohttp FastAPI',\n",
       " 'Airflow Argo Workflows Kubeflow',\n",
       " 'AkkaExperience',\n",
       " 'Allianz Group',\n",
       " 'Amazon',\n",
       " 'Amazon Athena',\n",
       " 'Amazon Athena Apache',\n",
       " 'Amazon Redshift',\n",
       " 'Amazon Redshift Big Query Ability',\n",
       " 'Amazon Redshift DBMS SQL',\n",
       " 'Amazon RedshiftExperience',\n",
       " 'Amazon Web Services',\n",
       " 'Amazons',\n",
       " 'Analysis',\n",
       " 'Analysis Interpretation Validation',\n",
       " 'Analytics Data',\n",
       " 'Andreessen Horowitz',\n",
       " 'Ansible Kubernetes',\n",
       " 'Ansible Salt Condent',\n",
       " 'Apache',\n",
       " 'Apache Airflow',\n",
       " 'Apache Airflow Apache Kafka Apache',\n",
       " 'Apache Hive Spark',\n",
       " 'Apache NiFi Apache Beam Flink',\n",
       " 'Apache Spark',\n",
       " 'Apache Spark Databricks',\n",
       " 'Apache Spark Kafka',\n",
       " 'Apache Zeppelin Spark',\n",
       " 'Architects Data Engineers',\n",
       " 'Assist',\n",
       " 'Assist QA',\n",
       " 'Astarta',\n",
       " 'Athena AWS EMR Apache SparkComfortable',\n",
       " 'Athena ProtobufThrift Silicon Valley Experience',\n",
       " 'Atlas GDPR',\n",
       " 'Azure',\n",
       " 'Azure AWSStrong',\n",
       " 'Azure Synapse Apache Spark Data Lake Data Bricks Data Factory Cosmos',\n",
       " 'Azure Table Queue Storage',\n",
       " 'AzureGood',\n",
       " 'AzureWork',\n",
       " 'BC Kiyanovskiy Fully',\n",
       " 'BENEFITSWere',\n",
       " 'BI',\n",
       " 'BI Big Data Teams',\n",
       " 'BI Data Analytics',\n",
       " 'BI Integration TPO',\n",
       " 'BIInformatica PowerCenter',\n",
       " 'BIScience Ciklum Enterprise Data Support Engineer',\n",
       " 'BS',\n",
       " 'BS Computer Science Mathematics Engineering Information Technology',\n",
       " 'BS MS Computer Science Remote',\n",
       " 'BSMS Computer Science Engineering',\n",
       " 'Backend Java Engineer',\n",
       " 'Basic',\n",
       " 'Beetroot Academy',\n",
       " 'BeetrootWe',\n",
       " 'Belarus',\n",
       " 'Big Data',\n",
       " 'Big Data Developer',\n",
       " 'Big Data Engineer',\n",
       " 'Big Data Hadoop',\n",
       " 'Big Data Infrastructure',\n",
       " 'Big Data Systems',\n",
       " 'Big Data cloud Solutions',\n",
       " 'BigData',\n",
       " 'BigData Engineer',\n",
       " 'BigData Redshift Snowflake Hive Strong',\n",
       " 'BigQuery Cloud Composer Data Fusion',\n",
       " 'BigQuery MSSQL',\n",
       " 'Birthday Medical insurance Full Sick',\n",
       " 'BirthdayMedical',\n",
       " 'Bonuses',\n",
       " 'Brenda',\n",
       " 'Business Intelligence',\n",
       " 'Business Intelligence Artificial Intelligence',\n",
       " 'Business Intelligence Visualization Tool PowerBI',\n",
       " 'Business IntelligenceAnalytical',\n",
       " 'C++Our',\n",
       " 'CICD',\n",
       " 'CNN LSTM',\n",
       " 'COVID Unlimited',\n",
       " 'CS',\n",
       " 'CTO',\n",
       " 'CTO UAE Team',\n",
       " 'CV',\n",
       " 'CV NLP',\n",
       " 'California',\n",
       " 'Canada Mining domain',\n",
       " 'CanadaTOGETHER',\n",
       " 'CanadaThe',\n",
       " 'Card Industry Data Security Standard',\n",
       " 'Cassandra',\n",
       " 'Cassandra Commercial',\n",
       " 'Cassandra Data Warehouses AWS Azure GCP',\n",
       " 'Cassandra Mesos Kafka',\n",
       " 'Cassandra Redshift Cloud',\n",
       " 'Cassandra Technologies RabbitMQ',\n",
       " 'Certified Google Professional Data Engineer',\n",
       " 'Challenging projects Certifications Comfortable',\n",
       " 'ChatFood',\n",
       " 'Chef Puppet',\n",
       " 'Ciklum',\n",
       " 'Ciklum Cross Borders',\n",
       " 'Ciklum Digital',\n",
       " 'CiklumCiklum Software Engineering Solutions Company',\n",
       " 'Ciklumers',\n",
       " 'ClickHouse Druid BigQuery Redshift',\n",
       " 'Client Ciklum Data Engineer Data Warehouse',\n",
       " 'Cloud Composer Airflow',\n",
       " 'Club IT Club Loyalty Program Business New York',\n",
       " 'CoE',\n",
       " 'CockroachDB',\n",
       " 'CodeDeploy',\n",
       " 'Collaborate Data Scientists',\n",
       " 'Company Svitla Systems',\n",
       " 'Competitive Career',\n",
       " 'Computer Science',\n",
       " 'Computer Science Engineering Bioinformatics',\n",
       " 'Computer Science Engineering DevOps Team',\n",
       " 'Continuous Integration Continuous Delivery',\n",
       " 'Cooperate',\n",
       " 'Corporate Perks',\n",
       " 'Corporate eventsAbout Dynamics',\n",
       " 'Correction',\n",
       " 'Create Databusiness',\n",
       " 'Cross',\n",
       " 'DAG',\n",
       " 'DBMS',\n",
       " 'DBT',\n",
       " 'DS Strong',\n",
       " 'DWH',\n",
       " 'DWH Big Data AWS Solutions Architect VP Engineering',\n",
       " 'DWH ETL',\n",
       " 'DWHBI',\n",
       " 'Dagster Serverless',\n",
       " 'Daily lunchesResponsibilities',\n",
       " 'Data',\n",
       " 'Data Analysis Preparation Development Deep Learning Machine Learning Computer Vision',\n",
       " 'Data Analysts Data Engineers Product Delivery Manager Participate',\n",
       " 'Data Analytics',\n",
       " 'Data BI Engineers Program Managers Analysts',\n",
       " 'Data Data',\n",
       " 'Data Eagerness',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer Data',\n",
       " 'Data Engineer Database Developer Experience RDBMSs Oracle',\n",
       " 'Data Engineer Products Data Engineer',\n",
       " 'Data Engineering Data Warehousing',\n",
       " 'Data Engineering Familiarity',\n",
       " 'Data Engineering Team',\n",
       " 'Data Integration',\n",
       " 'Data Lake Develop Spark',\n",
       " 'Data Lake Store Azure Blob Storage Azure SQL Data',\n",
       " 'Data Lake Store Azure Blob Storage Plus Excellent',\n",
       " 'Data Management Developing',\n",
       " 'Data Modeling Data Warehouse',\n",
       " 'Data Products Code Build',\n",
       " 'Data Quality',\n",
       " 'Data Quality Engineer BI Data Quality EngineerQA',\n",
       " 'Data Quality Engineer Data Quality Engineer',\n",
       " 'Data Science AI',\n",
       " 'Data Science Machine Learning',\n",
       " 'Data Structuring',\n",
       " 'Data Structuring Support Sales Team',\n",
       " 'Data Validation Data QA Pipelines',\n",
       " 'Data Warehouse',\n",
       " 'Data Warehouse Team',\n",
       " 'Data Warehouse conceptsSchema',\n",
       " 'Data WarehouseData Integration Knowledge',\n",
       " 'Data Warehousing Analytics',\n",
       " 'Data platforms',\n",
       " 'DataPrep Cloud Data Fusion',\n",
       " 'Databases Infrastructure Monitor',\n",
       " 'Databricks Delta Lake',\n",
       " 'Datainformation',\n",
       " 'DatapipelinesAirflow',\n",
       " 'Dataproc GKE Design',\n",
       " 'Datawarehouse SQL',\n",
       " 'Decision Intelligence',\n",
       " 'DegreeBesides',\n",
       " 'Deliver services Global Data Platform GDP',\n",
       " 'Design Data Architectural',\n",
       " 'DesignWorking Agile',\n",
       " 'DevOps',\n",
       " 'DevOps Engineer',\n",
       " 'DevOps Team',\n",
       " 'Develop',\n",
       " 'Develop CICD Engineering Data Science',\n",
       " 'Develop ETL',\n",
       " 'Development CICD',\n",
       " 'DevelopmentWe',\n",
       " 'DevelopmentWe Business Management Schools',\n",
       " 'Docker',\n",
       " 'Docker Kubernetes',\n",
       " 'Docker Kubernetes Microservice',\n",
       " 'Docker SQL Server',\n",
       " 'Docker Strong',\n",
       " 'DockerEnglish',\n",
       " 'Dockers Graph',\n",
       " 'Doxyme Good',\n",
       " 'Dremio',\n",
       " 'Dynamic',\n",
       " 'DynamoDBFamiliarity',\n",
       " 'ECR',\n",
       " 'ELK',\n",
       " 'ELT',\n",
       " 'EMR',\n",
       " 'EMR AirFlow Kinesis BigQueryPrevious',\n",
       " 'ETL',\n",
       " 'ETL Experience Google Cloud',\n",
       " 'ETL Extract Transform Load Data',\n",
       " 'ETLELT',\n",
       " 'ETLELT Data Quality Data Management Preferable',\n",
       " 'ETLELT Data Quality Data Managementeg Apache Airflow Apache Kafka Apache SparkExperience',\n",
       " 'ETLsUnderstanding TDD',\n",
       " 'EXPERIENCEMUST',\n",
       " 'EXPERIENCEMUST HAVE5',\n",
       " 'Elasticsearch',\n",
       " 'Elasticsearch Hadoop MongoDB',\n",
       " 'Engineer',\n",
       " 'Engineer DBA MS',\n",
       " 'EngineerQualifications Experience-Fluent Python',\n",
       " 'EngineeringSolid',\n",
       " 'Engineers Designers Business Intelligence HelloFreshs',\n",
       " 'English',\n",
       " 'English Azure Event Azure Data Lake',\n",
       " 'English Level Upper-Intermediate',\n",
       " 'EnglishAbility',\n",
       " 'EnglishExperience Postman',\n",
       " 'EnglishGerman',\n",
       " 'EnglishOur Work Doxyme',\n",
       " 'EnglishResponsibilities',\n",
       " 'EnglishSnowflake FivetranDataArt',\n",
       " 'EnglishWe',\n",
       " 'EnglishWell',\n",
       " 'EnglishWillingness',\n",
       " 'Enterprise Data Warehouse Data Modeling Data Architectures',\n",
       " 'Europe',\n",
       " 'Europe United States',\n",
       " 'Europes',\n",
       " 'Excel Tableau SQL Linux',\n",
       " 'Experience CICD Knowledge',\n",
       " 'Experience Cloud Data Management Engineering',\n",
       " 'Experience Test DocumentationArtifacts Senior',\n",
       " 'Experimentation',\n",
       " 'Extract Load Transform',\n",
       " 'Facebook Google',\n",
       " 'FactoryData',\n",
       " 'Familiarity AWS',\n",
       " 'Familiarity Adtech',\n",
       " 'Familiarity Aerospike',\n",
       " 'Familiarity Python',\n",
       " 'Familiarity Visual Studio',\n",
       " 'Feature Team',\n",
       " 'Fiddler Charles',\n",
       " 'Firebolt',\n",
       " 'Fitness',\n",
       " 'Fivetran Stitch',\n",
       " 'Flask Falcon',\n",
       " 'Fluency Python',\n",
       " 'Focus data',\n",
       " 'Fractal Kyiv',\n",
       " 'FranceOur',\n",
       " 'Free English',\n",
       " 'Fridge',\n",
       " 'GCP',\n",
       " 'GCP BigData Engineer',\n",
       " 'GCPAWS',\n",
       " 'GCS BigQuery',\n",
       " 'GCloud Azure Exchange',\n",
       " 'GPC',\n",
       " 'Gemfire IBM',\n",
       " 'German',\n",
       " 'Git AWS',\n",
       " 'Git English',\n",
       " 'Git Github Wiki',\n",
       " 'Git Jira TestRail Postman',\n",
       " 'Git LinuxWhat',\n",
       " 'Gitlab Jenkins Strong',\n",
       " 'Glue Athena Redshift Hands',\n",
       " 'Golang Docker',\n",
       " 'GolangBackground',\n",
       " 'Google AnalyticsTag',\n",
       " 'Google Cloud',\n",
       " 'Google CloudAWS Docker',\n",
       " 'Google Intel',\n",
       " 'Google Play US App Store Top Charts',\n",
       " 'Grafana Kibana',\n",
       " 'GrafanaAbout BSMaster Computer Science Engineering',\n",
       " 'GrafanaExperience Scala',\n",
       " 'Grammarly',\n",
       " 'Graph',\n",
       " 'Great Expectations Python',\n",
       " 'Groovy Spring Core Web Boot Data Engineer',\n",
       " 'GroupResponsibilities Capable Ownership Accountability Data Warehouse',\n",
       " 'HO',\n",
       " 'HQ Armenia Yerevan',\n",
       " 'Hadoop',\n",
       " 'Hadoop Hive',\n",
       " 'Hadoop Kafka',\n",
       " 'Hadoop Map Reduce Pig',\n",
       " 'Hadoop Spark',\n",
       " 'Hadoop Spark Pandas',\n",
       " 'HadoopGood',\n",
       " 'HadoopSpark',\n",
       " 'HadoopTechnical',\n",
       " 'Hbase Cassandra',\n",
       " 'HealthFitness',\n",
       " 'Healthcare',\n",
       " 'HelloFresh',\n",
       " 'Hive HiveQL-Good',\n",
       " 'Hive Kafka',\n",
       " 'HiveImpala',\n",
       " 'HiveSnowflakeOLAPHudi',\n",
       " 'Honda',\n",
       " 'Humanity Teamwork Development Innovation Analyze',\n",
       " 'IDP',\n",
       " 'IO TPL DataFlow pipelinesMicroservices',\n",
       " 'IP',\n",
       " 'ImpalaHadoop',\n",
       " 'Influence',\n",
       " 'Informatica Datastage SSIS',\n",
       " 'Ingenico AstraZeneca Ancestry Svitla',\n",
       " 'IntelliBoard Inc Data',\n",
       " 'IntelliBoard Inc EdTech',\n",
       " 'Intellias',\n",
       " 'Intelligence',\n",
       " 'Interface',\n",
       " 'Intermediate Upper-Intermediate',\n",
       " 'InternetCompanyYouScanio',\n",
       " 'Investigate ETL Assist',\n",
       " 'IoC',\n",
       " 'JDBC HTTP MQQTWork Application',\n",
       " 'JIRA Confluence OS UnixLinuxQualifications',\n",
       " 'JSON XML',\n",
       " 'JVM',\n",
       " 'JVM Java',\n",
       " 'Java',\n",
       " 'Java Experience',\n",
       " 'Java Python',\n",
       " 'Java Scala',\n",
       " 'Java Scala C++',\n",
       " 'Java Scala JavaScript',\n",
       " 'Java Scala Python',\n",
       " 'Java Scala PythonFamiliar Data',\n",
       " 'Java Scala Write',\n",
       " 'JavaScala',\n",
       " 'JavaScala Vertica Exasol Teradata RedshiftBigQuery Druid Clickhouse',\n",
       " 'Javaat',\n",
       " 'Javascript',\n",
       " 'Jenkins CICD',\n",
       " 'Jenkins NiFi',\n",
       " 'Jitterbit',\n",
       " 'Join Opportunity Svitla Systems Inc Senior Big Data Engineer',\n",
       " 'Jooble Instagram',\n",
       " 'Jupyter Notebook',\n",
       " 'Jupyter Notebook Zeppelin Apache Airflow',\n",
       " 'Jupyter R-Studio',\n",
       " 'KPIsBuild',\n",
       " 'KSQL Streams Kafka Connect Google Cloud Cloud Hadoop Google Dataflow Apache Beam BigQuery',\n",
       " 'Kafka',\n",
       " 'Kafka Amazon',\n",
       " 'Kafka Apache Spark Streaming Akka Streams Kafka Streams Storm RabbitMQ',\n",
       " 'Kafka Enjoy',\n",
       " 'Kafka Kinesis',\n",
       " 'Kafka NiFi',\n",
       " 'Kafka RabbitMQ',\n",
       " 'Kafka Spark',\n",
       " 'Kafka Spark Streaming',\n",
       " 'Kafka Spark Streaming Akka Streams Understanding',\n",
       " 'Kafka Spark Streaming Storm',\n",
       " 'Kafka Spark Streaming Strong',\n",
       " 'Kafka SparkCassandra AWS EC2 EMR ECS Kinesis',\n",
       " 'Kafka Stack Kafka Streams Kafka',\n",
       " 'Kafka Storm',\n",
       " 'Kafka Streams Spark Streaming Experience Cloud Platforms GCP AWS',\n",
       " 'Kafka Zookeeper Docker',\n",
       " 'KafkaExperience',\n",
       " 'KafkaRabbitMQApache MQ AMQP',\n",
       " 'Kimball ETL Concepts Using Data Integration',\n",
       " 'Kimball Inmon Hands-',\n",
       " 'Knime Microsofts MSSQL Integration Services',\n",
       " 'Knowledge Data',\n",
       " 'Knowledge Data Quality',\n",
       " 'Knowledge Data Warehouse Experience Data visualizationBusiness',\n",
       " 'Knowledge Data Warehousing',\n",
       " 'Knowledge Kubernetes',\n",
       " 'Knowledge Python',\n",
       " 'Kontraktova',\n",
       " 'Kontraktova Kyiv',\n",
       " 'Kontraktova Ploscha',\n",
       " 'Kontraktova PloschaThe Data Engineer',\n",
       " 'Kontraktova Ploshcha',\n",
       " 'Kotlin Dropwizard',\n",
       " 'KotlinJava',\n",
       " 'Kubernetes',\n",
       " 'Kubernetes Docker3rd',\n",
       " 'Kubernetes Hashicorp Nomad Advanced',\n",
       " 'Kubernetes Nomad Knowledge',\n",
       " 'KubernetesAs CICD',\n",
       " 'KubernetesKnowledge AWS',\n",
       " 'Kyiv',\n",
       " 'Kyiv city',\n",
       " 'Lagos',\n",
       " 'LakeDelta Lake Apache Spark Apache',\n",
       " 'LakesVariety',\n",
       " 'Lambda ECS Devops',\n",
       " 'Lambda Scala Python',\n",
       " 'LambdaKappa',\n",
       " 'Language school Compensation',\n",
       " 'Learn QA',\n",
       " 'Liaise',\n",
       " 'Library Gym Massage Sleeping',\n",
       " 'Linux Bash',\n",
       " 'Linux Kubernetes Docker',\n",
       " 'LinuxUnix OS',\n",
       " 'London KievWhat',\n",
       " 'Looker',\n",
       " 'LookerTableau BI',\n",
       " 'Loopback Team Technologists Academics Researchers Innovators',\n",
       " 'Lounge PlayStation VR',\n",
       " 'Loving GCP Azure AWS',\n",
       " 'Luigi Airow',\n",
       " 'Luigi JenkinsStorage',\n",
       " 'Luigi MLFlow',\n",
       " 'Lukyanivska',\n",
       " 'Lviv',\n",
       " 'Lviv Kyiv',\n",
       " 'Lviv KyivCollaborate',\n",
       " 'Lviv KyivDrive',\n",
       " 'Lviv KyivFor',\n",
       " 'Lviv KyivOur Backend Engineers',\n",
       " 'Lviv KyivSolve',\n",
       " 'Lviv KyivTaking',\n",
       " 'Lvivska',\n",
       " 'MI',\n",
       " 'ML',\n",
       " 'MLAI',\n",
       " 'MLAI Real',\n",
       " 'MacBook',\n",
       " 'MacBook Pro WindowsLinux',\n",
       " 'Machine Learning',\n",
       " 'Machine Learning AI',\n",
       " 'Machine Learning Artificial IntelligenceResponsibilities',\n",
       " 'Machine Learning Building',\n",
       " 'Machine Learning Data Science Familiar ML Experience',\n",
       " 'Machine Learning Data ScienceIntimate',\n",
       " 'Machine Learning Spark Sagemaker',\n",
       " 'Malta',\n",
       " 'MapReduce Hadoop Spark',\n",
       " 'Maternity',\n",
       " 'Maven CICD',\n",
       " 'Maven GradleWe',\n",
       " 'Meetups',\n",
       " 'Mexico',\n",
       " 'Microservice',\n",
       " 'Microsoft Azure',\n",
       " 'Microsoft Azure IAASPAASSAAS',\n",
       " 'Middle East',\n",
       " 'Middle Junior',\n",
       " 'MongoDBReactJS Docker',\n",
       " 'Monitor',\n",
       " 'Monitor Deploy Ensure',\n",
       " 'Monitoring',\n",
       " 'Munich',\n",
       " 'Must Classical Data Warehouse Data',\n",
       " 'MySQL MySQL Data Warehouse',\n",
       " 'MySQL Oracle',\n",
       " 'MySQL PostgreSQL',\n",
       " 'NLP',\n",
       " 'NLP Neutral Network',\n",
       " 'NLP Solid knowledge',\n",
       " 'NLP Work',\n",
       " 'Nairobi',\n",
       " 'Nasdaq GE Healthcare',\n",
       " 'New Year',\n",
       " 'New York',\n",
       " 'NiFi Java',\n",
       " 'Nifi ElasticSearchSOLR',\n",
       " 'NoSQL',\n",
       " 'NoSQL Coursera Khan Academy',\n",
       " 'NoSQL Elasticsearch Redis Knowledge',\n",
       " 'NoSQL MySQL PostgresSQL',\n",
       " 'NoSQL Strong',\n",
       " 'OOD OOP Design Microservices',\n",
       " 'ObjectsTableau Expirience',\n",
       " 'OctoberYour',\n",
       " 'Office Gulliver Nice',\n",
       " 'OpenVino TensorRT',\n",
       " 'Oracle Computer Science',\n",
       " 'Oracle Develop',\n",
       " 'Owns',\n",
       " 'PB',\n",
       " 'PE',\n",
       " 'PLUSAzure DatabricksDevOps',\n",
       " 'POSIX',\n",
       " 'PaaSSaaS',\n",
       " 'Palats Ukraine',\n",
       " 'Panda NumPy Pyodbc Psycopg2 AWS',\n",
       " 'Pandas',\n",
       " 'Paris',\n",
       " 'Partner BI',\n",
       " 'Perform QA',\n",
       " 'Perks',\n",
       " 'Personal Development PlanRegular',\n",
       " 'PhD',\n",
       " 'Platika Platika',\n",
       " 'PlayStation',\n",
       " 'Pluralsight',\n",
       " 'PoC',\n",
       " 'Podil',\n",
       " 'Poland',\n",
       " 'Preparation ProcessingOperationalize',\n",
       " 'Presto AWS',\n",
       " 'Presto Drill',\n",
       " 'Presto Hive',\n",
       " 'Project Management',\n",
       " 'Projects Team',\n",
       " 'Protobuf Parquet',\n",
       " 'PubSubETL',\n",
       " 'PySpark ScalaExperience',\n",
       " 'PySpark UDF',\n",
       " 'Python Airflow Kubernetes Docker CircleCi',\n",
       " 'Python Data EngineeringBI Development',\n",
       " 'Python Experience',\n",
       " 'Python Extensive',\n",
       " 'Python Java Spark',\n",
       " 'Python PysparkStrong',\n",
       " 'Python Rust',\n",
       " 'Python Strong',\n",
       " 'Python Team',\n",
       " 'Python3 Apache Airflow Apache Spark Apache Hadoop Apache Kafka',\n",
       " 'PythonC++JavaCIntermediate',\n",
       " 'PythonJava',\n",
       " 'PythonSolid',\n",
       " 'PythonWe',\n",
       " 'QA',\n",
       " 'QA Engineer',\n",
       " 'QC',\n",
       " 'QE',\n",
       " 'QPS',\n",
       " 'QualificationKnowledge',\n",
       " 'Qualifications15+years',\n",
       " 'RD',\n",
       " 'RD Monitor',\n",
       " 'RDBMS',\n",
       " 'RDMS',\n",
       " 'RDS',\n",
       " 'RESPONSIBILITIES Design',\n",
       " 'RESPONSIBILITIESDesign',\n",
       " 'Rabbit Knowledge',\n",
       " 'RedShift',\n",
       " 'Redis Elasticsearch',\n",
       " 'Redis Experience',\n",
       " 'Redis NET Core Docker Swarm',\n",
       " 'Redis VerticaFamiliarity',\n",
       " 'Redshift Lambda',\n",
       " 'Redshift Snowflake BigQuery',\n",
       " 'RedshiftExperience',\n",
       " 'RedshiftExpert',\n",
       " 'Reface',\n",
       " 'Reface Data Engineer',\n",
       " 'Remote',\n",
       " 'Requirement Testing Data Structuring',\n",
       " 'RequirementsBS+',\n",
       " 'Responsibilities Building Data Lake Google Cloud Platform Develop',\n",
       " 'Responsibilities Builds',\n",
       " 'Responsibilities Contributes',\n",
       " 'Review',\n",
       " 'Rokus DMM Digital Marketing Management',\n",
       " 'S3',\n",
       " 'S3 Redshift',\n",
       " 'S3 Redshift Airflow Challenging',\n",
       " 'S3 Redshift RDS Experience',\n",
       " 'SDET',\n",
       " 'SDLCSTLC',\n",
       " 'SFTP',\n",
       " 'SIM',\n",
       " 'SLA',\n",
       " 'SLQ',\n",
       " 'SQL',\n",
       " 'SQL BigData',\n",
       " 'SQL BigQuery',\n",
       " 'SQL BigQuery PubSub',\n",
       " 'SQL Comfortable',\n",
       " 'SQL Data Analysis',\n",
       " 'SQL Data Warehousing',\n",
       " 'SQL Familiarity',\n",
       " 'SQL Python',\n",
       " 'SQL SQL',\n",
       " 'SQL Scale',\n",
       " 'SQL Server Oracle',\n",
       " 'SQL ServerProject',\n",
       " 'SQL Strong',\n",
       " 'SQL Talend Elastic Spark Custom BuiltExperience',\n",
       " 'SQLAlchemyETL',\n",
       " 'SQLFamiliarity',\n",
       " 'SQLNoSQL',\n",
       " 'SQLNoSQL MySQL PostgreSQL',\n",
       " 'SSIS InformaticaWe',\n",
       " 'Salesforce',\n",
       " 'San Ramon',\n",
       " 'Scala',\n",
       " 'Scala Java',\n",
       " 'Scala Programming-Proficiency',\n",
       " 'Scala Python',\n",
       " 'Scala Spark Strong',\n",
       " 'Scala Working',\n",
       " 'ScalaInteresting',\n",
       " 'Scrum',\n",
       " 'Shoot CV',\n",
       " 'Silicon Valley',\n",
       " 'Sisense',\n",
       " 'Sisensers',\n",
       " 'Skills Cloud',\n",
       " 'SkillsCompetencies',\n",
       " 'SkillsCompetencies Work Higher Professional Educational',\n",
       " 'Slack Fiddler TestDriven',\n",
       " 'Snapchat Twitter',\n",
       " 'Snoop Dogg Miley',\n",
       " 'Snowflake BigQuery',\n",
       " 'Snowflake Databricks',\n",
       " 'Social',\n",
       " 'Social activities',\n",
       " 'SoftServe',\n",
       " 'Software Engineer',\n",
       " 'Software Engineer Data Platform',\n",
       " 'SpainAs Ciklum',\n",
       " 'Spark',\n",
       " 'Spark Excellent',\n",
       " 'Spark Hadoop',\n",
       " 'Spark KafkaExperience',\n",
       " 'Spark Kinesis Kafka',\n",
       " 'Spark Kubernetes Istio',\n",
       " 'Spark PySpark',\n",
       " 'Spark PythonPandas Awareness DevOps Hands',\n",
       " 'Spark Scala Load',\n",
       " 'Spark mapReduce Track',\n",
       " 'SparkFlinkPresto etcExperience',\n",
       " 'SparkHandling',\n",
       " 'SparkKnowledge',\n",
       " 'SparkPySparkScalaJava Experience',\n",
       " 'Spears Justin Bieber',\n",
       " 'Sport',\n",
       " 'SportTech',\n",
       " 'SportWe',\n",
       " 'Stack',\n",
       " 'Stack Python MS',\n",
       " 'Stack Python SQLProject Description Client',\n",
       " 'Star SnowflakeProcessing Paradigm Batch',\n",
       " 'State',\n",
       " 'StreamingStructured StreamingSparkSQLStrong',\n",
       " 'Strong Computer Science',\n",
       " 'Strong Python',\n",
       " 'Strong Python Familiar GCP Composer Airflow Cloud SQL PostgreSQL',\n",
       " 'Strong SQL Excel',\n",
       " 'SummaryDevelop Rokus',\n",
       " 'SummaryThe',\n",
       " 'SummaryWe Data Engineer',\n",
       " 'Support TA Data Science',\n",
       " 'Svitla Birthday',\n",
       " 'Switzerland',\n",
       " 'Synthesize',\n",
       " 'TDD SOLID Engineering Practices',\n",
       " 'TDDBDDMetrics Notifications',\n",
       " 'TRINETIX',\n",
       " 'TSE',\n",
       " 'Tableau Ability',\n",
       " 'Tableau Extensive',\n",
       " 'Tableau Mode Looker',\n",
       " 'Tableau PowerBI',\n",
       " 'Tableau Superset',\n",
       " 'Talend PowerBI',\n",
       " 'Taras Shevchenko',\n",
       " 'Team',\n",
       " 'Team Building USA Europe',\n",
       " 'TeamWere',\n",
       " 'Technology',\n",
       " 'Tel AvivKyiv',\n",
       " 'Tensorflow BigQuery',\n",
       " 'TeradataData Warehouse Engineer',\n",
       " 'Terraform',\n",
       " 'Terraform Ansibleor',\n",
       " 'Terraform Cloudfront',\n",
       " 'Terraform Jenkins',\n",
       " 'Thrasio Skills Experience Data',\n",
       " 'Tokbox Pubnub Twilio StripeLegacy',\n",
       " 'Tree MVCC',\n",
       " 'UA',\n",
       " 'UAETeam',\n",
       " 'UI',\n",
       " 'UK',\n",
       " 'UML',\n",
       " 'US',\n",
       " 'US Dedicated HR Client',\n",
       " 'US Eastern Europe',\n",
       " 'US Equity Markets',\n",
       " 'USAWe',\n",
       " 'USBetterMe',\n",
       " 'Uklon',\n",
       " 'Ukraine',\n",
       " 'Ukraines',\n",
       " 'Understanding',\n",
       " 'UnitCity Medical',\n",
       " 'University degree Mathematics Physics Computer Science fieldHelpful',\n",
       " 'Upper Intermediate Cloud Computing Experience AWS',\n",
       " 'Upper-Intermediate',\n",
       " 'Upper-Intermediate Advanced',\n",
       " 'Upper-Intermediate Knowledge',\n",
       " 'Upper-Intermediate Knowledge Cassandra Architecture CQL Knowledge Java Programming Data',\n",
       " 'Upper-Intermediate Solid',\n",
       " 'VGS',\n",
       " 'VPC VPN Extreme',\n",
       " 'Veritca Greenplum Redshift SnowflakeSuccess',\n",
       " 'Verizon Philips',\n",
       " 'Vertica',\n",
       " 'Vertica Netezza Greenplum',\n",
       " 'Vienna',\n",
       " 'Vital Signs Monitor Childrens Cardiac Center Smart',\n",
       " 'Vystavkovyi',\n",
       " 'WFH',\n",
       " 'WarehouseExperience SQL',\n",
       " 'Welfare',\n",
       " 'WhereScape Expirience PythonWe',\n",
       " 'Xenoss',\n",
       " 'YouYou',\n",
       " 'Zero',\n",
       " 'backgroundOur Company',\n",
       " 'basisYou',\n",
       " 'changesRequirementsYou',\n",
       " 'dbtWe',\n",
       " 'details20',\n",
       " 'etcExperience',\n",
       " 'everywhereYou',\n",
       " 'experiencesResponsibilities',\n",
       " 'facilitiesDevelop',\n",
       " 'hours',\n",
       " 'hundreds millions',\n",
       " 'hundreds thousands',\n",
       " 'iMac MacBook',\n",
       " 'inComfort Linux',\n",
       " 'infrastructureKubernetesCICD JavaHigher Education',\n",
       " 'millions',\n",
       " 'modelsResponsibilitiesAs',\n",
       " 'prioritizeNow',\n",
       " 'processingCHALLENGES Development',\n",
       " 'productsCiCD Git Terraform Jenkins',\n",
       " 'qualityPrepare',\n",
       " 'requirementsOur',\n",
       " 'second',\n",
       " 'securityABOUT PRODUCTData Platform',\n",
       " 'standardsUse',\n",
       " 'storage30+ M',\n",
       " 'teamCommunicate PM PO Developers',\n",
       " 'tennisOur',\n",
       " 'thousands',\n",
       " 'working hours',\n",
       " 'zoneWhy Family'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
